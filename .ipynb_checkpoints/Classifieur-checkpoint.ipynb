{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'Abstract', 'Category']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "#Importer nos données \n",
    "\n",
    "data = open('train.csv')\n",
    "csv_file = csv.reader(data)\n",
    "data_points = []\n",
    "\n",
    "for row in csv_file:\n",
    "    data_points.append(row)\n",
    "print(data_points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astro-ph' 'astro-ph.CO' 'astro-ph.GA' 'astro-ph.SR' 'cond-mat.mes-hall'\n",
      " 'cond-mat.mtrl-sci' 'cs.LG' 'gr-qc' 'hep-ph' 'hep-th' 'math.AP' 'math.CO'\n",
      " 'physics.optics' 'quant-ph' 'stat.ML']\n"
     ]
    }
   ],
   "source": [
    "#INFO: 7500 données\n",
    "\n",
    "id_data = []\n",
    "for i in range(len(data_points)):\n",
    "    id_data.append(data_points[i][0])\n",
    "    \n",
    "id_data.pop(0)\n",
    "\n",
    "abstract_data = [] #\n",
    "for i in range(len(data_points)):\n",
    "    abstract_data.append(data_points[i][1])\n",
    "\n",
    "abstract_data.pop(0)\n",
    "\n",
    "category_data = []\n",
    "for i in range(len(data_points)):\n",
    "    category_data.append(data_points[i][2])\n",
    "\n",
    "category_data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]\n"
     ]
    }
   ],
   "source": [
    "#On commpte le nombre d'instance de chaque classe\n",
    "\n",
    "classe = np.unique(category_data)\n",
    "\n",
    "counts = []\n",
    "\n",
    "#On crée une liste du nombre d'occurrences des classes\n",
    "for x in range(len(classe)):\n",
    "    counts.append(0)\n",
    "\n",
    "#On compte le nombre de classes dans nos données\n",
    "where = []\n",
    "for x in range(len(category_data)):\n",
    "    where = np.where(classe ==category_data[x])\n",
    "    counts[where[0][0]] += 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]\n"
     ]
    }
   ],
   "source": [
    "#Probabilité d'avoir une classe X dans nos données, prior P(c)\n",
    "\n",
    "prior = []\n",
    "\n",
    "for x in counts:\n",
    "    prior.append(x/len(category_data))\n",
    "print(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mercu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mercu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords #On importe les mots à rétirer\n",
    "from nltk.tokenize import word_tokenize #Module pour séparer les éléments\n",
    "from nltk.probability import FreqDist #Module pour compter la fréquence\n",
    "\n",
    "#Compter le nombre de mot de chaque classe\n",
    "\n",
    "extract = []\n",
    "vocabulaire = []\n",
    "banned_word = stopwords.words('english')\n",
    "\n",
    "#À améliorer\n",
    "banned_word.append('.')\n",
    "banned_word.append(',')\n",
    "\n",
    "def extraction(phrase):\n",
    "    for m in word_tokenize(phrase):\n",
    "        if m.lower() not in banned_word:\n",
    "            extract.append(m)\n",
    "    return extract #retourne une list de mots\n",
    "\n",
    "bag = {}\n",
    "\n",
    "#Nombre d'occurences total pour tous les mots selon une classe\n",
    "def sac_de_mot_general(sac,classe):\n",
    "    for i in range(len(sac)):\n",
    "        if classe == sac[i][2]:\n",
    "            mots = extraction(sac[i][1])\n",
    "            for mot in mots:\n",
    "                if mot not in bag.keys():\n",
    "                    bag[mot] = 1\n",
    "                else:\n",
    "                    bag[mot] += 1\n",
    "    return bag\n",
    "        \n",
    "sac_de_mot_general(data_points,\"cs.LG\")\n",
    "\n",
    "#Nombre d'occurences total pour un article\n",
    "def sac_de_mot(sac):\n",
    "    for text in sac:\n",
    "        mots = extraction(text)\n",
    "        for mot in mots:\n",
    "            if mot not in bag.keys():\n",
    "                bag[mot] = 1\n",
    "            else:\n",
    "                bag[mot] += 1\n",
    "    return bag\n",
    "\n",
    "\n",
    "#Probabillité d'avoir un mot sachant une classe, vraisemblance P(c/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
